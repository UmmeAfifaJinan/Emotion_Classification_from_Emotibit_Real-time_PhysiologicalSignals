import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings("ignore")
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn import svm
from sklearn.impute import SimpleImputer
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.svm import SVC
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef
from sklearn.base import clone
from matplotlib import pyplot as plt
import seaborn as sns 

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    print(dirname)
    #print('**********************************')
    print(filenames)
    #print('**********************************')
    for filename in filenames:
        print(os.path.join(dirname, filename)) 

ecg_path = '/kaggle/input/vr-eyes-emotions-dataset-vreed/05 ECG-GSR Data/02 ECG-GSR (Features Extracted)/ECG_FeaturesExtracted.csv'
gsr_path = '/kaggle/input/vr-eyes-emotions-dataset-vreed/05 ECG-GSR Data/02 ECG-GSR (Features Extracted)/GSR_FeaturesExtracted.csv' 

ecg_df = pd.read_csv(ecg_path)
gsr_df = pd.read_csv(gsr_path) 


#ECG


ecg_df.tail() 

ecg_df = pd.read_csv(ecg_path)
ecg_df.columns 

ecg_corr = ecg_df.corr()
sns.heatmap(ecg_corr) 

ecg_df.Quad_Cat 

data_reduced_ecg = ecg_df.copy() 

# Using the .replace() method, we can change the values in the target column
data_reduced_ecg = data_reduced_ecg.replace({'Quad_Cat' : {1: 0}})
data_reduced_ecg = data_reduced_ecg.replace({'Quad_Cat' : {2: 1, 3: 1}}) 

train_set, test_set = train_test_split(data_reduced_ecg, test_size=0.2, random_state=42) 

train_set.info() 

train_set 

train_set.loc[train_set.isnull().any(axis=1)] 

train_set.describe() 

from sklearn.base import clone
from sklearn.metrics import f1_score

def cv_score_ecg(X_train, y_train, clf, skfolds):
    
    y_pred = np.zeros_like(y_train)
    
    cv_score_list = []
    
    for train_indices, val_indices in skfolds.split(X_train, y_train):
        
        clone_clf = clone(clf)
        X_train_fold= X_train[train_indices]
        y_train_fold = y_train[train_indices]
        
        X_val_fold = X_train[val_indices]
        y_val_fold = y_train[val_indices]
        
        clone_clf.fit(X_train_fold, y_train_fold)
        y_p = clone_clf.predict(X_val_fold)
        
        y_pred[val_indices] = y_p
        
        # cv_score_list.append(np.sum(y_p == y_val_fold) / len(y_val_fold))
        cv_score_list.append(f1_score(y_val_fold, y_p))
        
    return {"y_pred" : y_pred, "cv_scores" : cv_score_list} 

train_predictors = train_set.drop("Quad_Cat", axis=1)
train_labels = train_set["Quad_Cat"].copy()

test_predictors = train_set.drop("Quad_Cat", axis=1)
test_labels = train_set["Quad_Cat"].copy() 

num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy="constant", fill_value=0)),
    ('std_scaler', StandardScaler())
]) 

num_attribs = list(train_set.columns)[1:]


full_pipeline = ColumnTransformer([
    ("num", num_pipeline, num_attribs)]) 

train_X = full_pipeline.fit_transform(train_predictors)
train_y = train_labels.values 

test_X = full_pipeline.transform(test_predictors)
test_y = test_labels.values 

skfolds_ecg = StratifiedKFold(n_splits=5, random_state=42, shuffle=True) 

rf_clf = RandomForestClassifier(random_state=42)

rf_cv_results = cv_score_ecg(train_X, train_y, rf_clf, skfolds)
# rf_cv_score = np.sum(rf_cv_results["y_pred"] == train_y) / len(train_y)
rf_cv_score = f1_score(train_y, rf_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(rf_cv_results["cv_scores"], rf_cv_score) ) 

sgd_clf = SGDClassifier(random_state=42)

sgd_cv_results = cv_score_ecg(train_X, train_y, sgd_clf, skfolds)
#  sgd_cv_score = np.sum(sgd_cv_results["y_pred"] == train_y) / len(train_y)
sgd_cv_score = f1_score(train_y, sgd_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(sgd_cv_results["cv_scores"], sgd_cv_score) ) 

svc_clf = SVC(random_state=42)

svc_cv_results = cv_score_ecg(train_X, train_y, svc_clf, skfolds)
# svc_cv_score = np.sum(svc_cv_results["y_pred"] == train_y) / len(train_y)
svc_cv_score = f1_score(train_y, svc_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(svc_cv_results["cv_scores"], svc_cv_score) ) 

knn_clf = KNeighborsClassifier()

knn_cv_results = cv_score_ecg(train_X, train_y, knn_clf, skfolds)
knn_cv_score = f1_score(train_y, knn_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(knn_cv_results["cv_scores"], knn_cv_score) ) 

gb_clf = GradientBoostingClassifier()

gb_cv_results = cv_score_ecg(train_X, train_y, gb_clf, skfolds)
gb_cv_score = f1_score(train_y, gb_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(gb_cv_results["cv_scores"], gb_cv_score) ) 

lr_clf = LogisticRegression(random_state=42)

lr_cv_results = cv_score_ecg(train_X, train_y, lr_clf, skfolds)
# lr_cv_score = np.sum(lr_cv_results["y_pred"] == train_y) / len(train_y)
lr_cv_score = f1_score(train_y, lr_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(lr_cv_results["cv_scores"], lr_cv_score) ) 

lr_ecg_cm = confusion_matrix(lr_cv_results["y_pred"], train_y, labels=[0, 1])
sgd_ecg_cm = confusion_matrix(sgd_cv_results["y_pred"], train_y, labels=[0, 1])
svc_ecg_cm = confusion_matrix(svc_cv_results["y_pred"], train_y, labels=[0, 1])
knn_ecg_cm = confusion_matrix(knn_cv_results["y_pred"], train_y, labels=[0, 1])
gb_ecg_cm = confusion_matrix(gb_cv_results["y_pred"], train_y, labels=[0, 1])
rf_ecg_cm = confusion_matrix(rf_cv_results["y_pred"], train_y, labels=[0, 1]) 

fig = plt.figure(figsize=(13, 3))

ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

sns.heatmap(data=lr_ecg_cm, annot=True, ax=ax1)
sns.heatmap(data=sgd_ecg_cm, annot=True, ax=ax2)
sns.heatmap(data=svc_ecg_cm, annot=True, ax=ax3)

ax1.set_ylabel("Actual class")
ax1.set_xlabel("Predicted class")
ax2.set_xlabel("Predicted class")
ax3.set_xlabel("Predicted class")

ax1.set_title("Logistic Regression, \n cv F1 score: " + str(round(lr_cv_score, 2)))
ax2.set_title("SGD, \n cv F1 score: " + str(round(sgd_cv_score, 2)))
ax3.set_title("SVC, \n cv F1 score: " + str(round(svc_cv_score, 2)))

plt.show() 

fig = plt.figure(figsize=(13, 3))

ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

sns.heatmap(data=knn_ecg_cm, annot=True, ax=ax1)
sns.heatmap(data=gb_ecg_cm, annot=True, ax=ax2)
sns.heatmap(data=rf_ecg_cm, annot=True, ax=ax3)

ax1.set_ylabel("Actual class")
ax1.set_xlabel("Predicted class")
ax2.set_xlabel("Predicted class")
ax3.set_xlabel("Predicted class")

ax1.set_title("KNN, \n cv F1 score: " + str(round(knn_cv_score, 2)))
ax2.set_title("GB, \n cv F1 score: " + str(round(gb_cv_score, 2)))
ax3.set_title("RF, \n cv F1 score: " + str(round(rf_cv_score, 2)))

plt.show() 

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report
rf_cm = confusion_matrix(y_pred, test_lbl) 

rf_cm 

classes=['HAHV', 'LAHV', 'LALV', 'HALV'] 
#HAHV=HighArousalHighValence, LAHV=LowArousalHighValence, LALV=LowArousalLowValence, HALV=HighArousalLowValence

disp = ConfusionMatrixDisplay(confusion_matrix=rf_cm, display_labels=classes)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix', fontsize=15, pad=20)
plt.xlabel('Prediction', fontsize=11)
plt.ylabel('Actual', fontsize=11)
#Customizations
plt.gca().xaxis.set_label_position('top')
plt.gca().xaxis.tick_top()
plt.gca().figure.subplots_adjust(bottom=0.2)
plt.gca().figure.text(0.5, 0.05, 'Prediction', ha='center', fontsize=13)

plt.show() 

print(classification_report(y_pred, test_lbl, target_names=classes)) 



#GSR



gsr_corr = gsr_df.corr()
sns.heatmap(gsr_corr) 

# We define a new dataset
data_reduced_gsr = gsr_df.copy() 

# Using the .replace() method, we can change the values in the target column
data_reduced_gsr = data_reduced_gsr.replace({'Quad_Cat' : {1: 0}})
data_reduced_gsr = data_reduced_gsr.replace({'Quad_Cat' : {2: 1, 3: 1}}) 

train_set, test_set = train_test_split(data_reduced_gsr, test_size=0.2, random_state=42) 

train_set.info() 

train_set.loc[train_set.isnull().any(axis=1)] 

train_set.describe() 

train_predictors = train_set.drop("Quad_Cat", axis=1)
train_labels = train_set["Quad_Cat"].copy()

test_predictors = train_set.drop("Quad_Cat", axis=1)
test_labels = train_set["Quad_Cat"].copy() 

num_attribs = list(train_set.columns)[1:]


full_pipeline = ColumnTransformer([
    ("num", num_pipeline, num_attribs)]) 

train_X = full_pipeline.fit_transform(train_predictors)
train_y = train_labels.values 

test_X = full_pipeline.transform(test_predictors)
test_y = test_labels.values 

rf_clf = RandomForestClassifier(random_state=42)

rf_cv_results = cv_score(train_X, train_y, rf_clf, skfolds)
# rf_cv_score = np.sum(rf_cv_results["y_pred"] == train_y) / len(train_y)
rf_cv_score = f1_score(train_y, rf_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(rf_cv_results["cv_scores"], rf_cv_score) ) 

sgd_clf = SGDClassifier(random_state=42)

sgd_cv_results = cv_score(train_X, train_y, sgd_clf, skfolds)
#  sgd_cv_score = np.sum(sgd_cv_results["y_pred"] == train_y) / len(train_y)
sgd_cv_score = f1_score(train_y, sgd_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(sgd_cv_results["cv_scores"], sgd_cv_score) ) 

svc_clf = SVC(random_state=42)

svc_cv_results = cv_score(train_X, train_y, svc_clf, skfolds)
# svc_cv_score = np.sum(svc_cv_results["y_pred"] == train_y) / len(train_y)
svc_cv_score = f1_score(train_y, svc_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(svc_cv_results["cv_scores"], svc_cv_score) ) 

knn_clf = KNeighborsClassifier()

knn_cv_results = cv_score(train_X, train_y, knn_clf, skfolds)
knn_cv_score = f1_score(train_y, knn_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(knn_cv_results["cv_scores"], knn_cv_score) ) 

gb_clf = GradientBoostingClassifier()

gb_cv_results = cv_score(train_X, train_y, gb_clf, skfolds)
gb_cv_score = f1_score(train_y, gb_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(gb_cv_results["cv_scores"], gb_cv_score) ) 

lr_clf = LogisticRegression(random_state=42)

lr_cv_results = cv_score(train_X, train_y, lr_clf, skfolds)
# lr_cv_score = np.sum(lr_cv_results["y_pred"] == train_y) / len(train_y)
lr_cv_score = f1_score(train_y, lr_cv_results["y_pred"])

print( "F1 score for each fold: \n{}\n \nOverall F1 score: {}".format(lr_cv_results["cv_scores"], lr_cv_score) ) 

lr_gsr_cm = confusion_matrix(lr_cv_results["y_pred"], train_y, labels=[0, 1])
sgd_gsr_cm = confusion_matrix(sgd_cv_results["y_pred"], train_y, labels=[0, 1])
svc_gsr_cm = confusion_matrix(svc_cv_results["y_pred"], train_y, labels=[0, 1])
knn_gsr_cm = confusion_matrix(knn_cv_results["y_pred"], train_y, labels=[0, 1])
gb_gsr_cm = confusion_matrix(gb_cv_results["y_pred"], train_y, labels=[0, 1])
rf_gsr_cm = confusion_matrix(rf_cv_results["y_pred"], train_y, labels=[0, 1]) 

fig = plt.figure(figsize=(13, 3))

ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

sns.heatmap(data=lr_gsr_cm, annot=True, ax=ax1)
sns.heatmap(data=sgd_gsr_cm, annot=True, ax=ax2)
sns.heatmap(data=svc_gsr_cm, annot=True, ax=ax3)

ax1.set_ylabel("Actual class")
ax1.set_xlabel("Predicted class")
ax2.set_xlabel("Predicted class")
ax3.set_xlabel("Predicted class")

ax1.set_title("Logistic Regression, \n cv F1 score: " + str(round(lr_cv_score, 2)))
ax2.set_title("SGD, \n cv F1 score: " + str(round(sgd_cv_score, 2)))
ax3.set_title("SVC, \n cv F1 score: " + str(round(svc_cv_score, 2)))

plt.show() 

fig = plt.figure(figsize=(13, 3))

ax1 = fig.add_subplot(131)
ax2 = fig.add_subplot(132)
ax3 = fig.add_subplot(133)

sns.heatmap(data=knn_gsr_cm, annot=True, ax=ax1)
sns.heatmap(data=gb_gsr_cm, annot=True, ax=ax2)
sns.heatmap(data=rf_gsr_cm, annot=True, ax=ax3)

ax1.set_ylabel("Actual class")
ax1.set_xlabel("Predicted class")
ax2.set_xlabel("Predicted class")
ax3.set_xlabel("Predicted class")

ax1.set_title("KNN, \n cv F1 score: " + str(round(knn_cv_score, 2)))
ax2.set_title("GB, \n cv F1 score: " + str(round(gb_cv_score, 2)))
ax3.set_title("RF, \n cv F1 score: " + str(round(rf_cv_score, 2)))

plt.show() 

